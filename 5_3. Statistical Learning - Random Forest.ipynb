{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3.1: Tree-Based Methods for Regression and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRandom forest\\n    regression / classification\\n    \\n1. tree based method \\n    - several tress making decision\\n    - graph theory - collection of trees is called forest\\n    - not identical to have all similar tree as it will give same prediction\\n    - forest are randomised\\n    - dividing predictor space using simple regions using straight line\\n    - again divide in sub-region so on continue till we hit some criteria - recursive\\n    - to predict for unseen test observation \\n        - find region of predictor space where test observation falls\\n        - regression : mean of the outcome observation\\n        - classification : mode of the outcome of training observation\\n        - slice to divide predictors space into regions \\n            - slice must be align with direction of axis of prediction space\\n            - higher dimensions - line becomes plane , so high dimension rectangles or boxes\\n            - how to decide where to cut - \\n                - carve out regions that are homogeneous\\n                predicted outcome - mean/mode for unseen observations\\n            - split : we consider all -  x1 to xp and their possible cut points\\n                - select cu point such a way that it has lowest criterian \\n                - loss function - try to minimize\\n                - regression : RSS\\n                - classification : Gini index, Cross entropy\\n    \\n    x1 , x2\\n        x1 = 0 to 10, x1=6 0,1\\n        \\n        x1<6  x1>=6\\n              /              x<8  x>=8   subdivision\\n            \\n            regions - based on mode\\n    \\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Random forest\n",
    "    regression / classification\n",
    "    \n",
    "1. tree based method \n",
    "    - several tress making decision\n",
    "    - graph theory - collection of trees is called forest\n",
    "    - not identical to have all similar tree as it will give same prediction\n",
    "    - forest are randomised\n",
    "    - dividing predictor space using simple regions using straight line\n",
    "    - again divide in sub-region so on continue till we hit some criteria - recursive\n",
    "    - to predict for unseen test observation \n",
    "        - find region of predictor space where test observation falls\n",
    "        - regression : mean of the outcome observation\n",
    "        - classification : mode of the outcome of training observation\n",
    "        - slice to divide predictors space into regions \n",
    "            - slice must be align with direction of axis of prediction space\n",
    "            - higher dimensions - line becomes plane , so high dimension rectangles or boxes\n",
    "            - how to decide where to cut - \n",
    "                - carve out regions that are homogeneous\n",
    "                predicted outcome - mean/mode for unseen observations\n",
    "            - split : we consider all -  x1 to xp and their possible cut points\n",
    "                - select cu point such a way that it has lowest criterian \n",
    "                - loss function - try to minimize\n",
    "                - regression : RSS\n",
    "                - classification : Gini index, Cross entropy\n",
    "    \n",
    "    x1 , x2\n",
    "        x1 = 0 to 10, x1=6 0,1\n",
    "        \n",
    "        x1<6  x1>=6\n",
    "              /  \\\n",
    "            x<8  x>=8   subdivision\n",
    "            \n",
    "            regions - based on mode\n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3.2 Random Forest Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Aggregate several trees to form a forest\n",
    "    prediction of random forest - combines prediction from individual trees\n",
    "    \n",
    "    regression setting - mean\n",
    "    classification setting - mode\n",
    "    \n",
    "    Randomness - 2 types (gives us more reliable method)\n",
    "    1. randomness to data - each tree fit to dataset \n",
    "        - bootstrap aggregation - bagging\n",
    "        - resampling method - repeatedly drawing samples from training  set and refeed model\n",
    "        - n observations - random select n observation with replacement with original dataset\n",
    "        - same observation can happen multiple times - so need to consider number of observation and fit to each tree\n",
    "    2. randomness in how we split the predictor space \n",
    "        - consider while making split at any point in given tree\n",
    "        - dicision tree - consider each predictor and cut point combination while making prediction space\n",
    "        - here, we dont consider all predictor but draw a small random sample . only allow to use these predictor to split\n",
    "        - each time we take new samples - effective\n",
    "        - ex: 1000 observation - 9 predictors - build 50 trees\n",
    "            - 50 bootstrap samples - separate tree\n",
    "            - 1st tree 1st cut - 3 predictor - best cut for 1, then 2, then 3rd \n",
    "            - repeat\n",
    "            \n",
    "    sklearn:\n",
    "    \n",
    "    One of the great features of the sklearn library is that there is a consistent framework \n",
    "    for the workflow needed to use different statistical models.\n",
    "\n",
    "    To do random forest regression, you use the following import:\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    To do random forest classification, you use the following import:\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    After importing the relevant model, everything proceeds in the same way \n",
    "    as for linear and logistic regression as shown in the previous notes.\n",
    "    \n",
    "    \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
